{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jose\\AppData\\Local\\Temp\\ipykernel_16452\\2396692039.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['text'] = data['text'].str.lower().str.replace('[^a-z\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Preparación de Datos\n",
    "data = pd.read_csv('data/normalized_merged_data.csv')\n",
    "data['text'] = data['text'].str.lower().str.replace('[^a-z\\s]', '')\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "train_encodings = tokenizer(train['text'].tolist(), truncation=True, padding='max_length', max_length=25, return_tensors='tf')\n",
    "val_encodings = tokenizer(val['text'].tolist(), truncation=True, padding='max_length', max_length=25, return_tensors='tf')\n",
    "test_encodings = tokenizer(test['text'].tolist(), truncation=True, padding='max_length', max_length=25, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# 2. Definición del Modelo\n",
    "base_model = TFGPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
    "input_layer = tf.keras.layers.Input(shape=(25,), dtype=tf.int32)\n",
    "sequence_output = base_model(input_layer)[0]\n",
    "cls_token = sequence_output[:, 0, :]\n",
    "content_head = tf.keras.layers.Dense(1, activation='sigmoid', name='content')(cls_token)\n",
    "wording_head = tf.keras.layers.Dense(1, activation='sigmoid', name='wording')(cls_token)\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=[content_head, wording_head])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 17/144 [==>...........................] - ETA: 1:35:32 - loss: 0.6729 - content_loss: 0.5251 - wording_loss: 0.1478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Entrenamiento\n",
    "model.fit(train_encodings['input_ids'], [train['normalized_content'], train['normalized_wording']], validation_data=(val_encodings['input_ids'], [val['normalized_content'], val['normalized_wording']]), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluación\n",
    "losses = model.evaluate(test_encodings['input_ids'], [test['normalized_content'], test['normalized_wording']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Predicción\n",
    "new_text = [\"Tu texto aquí\"]\n",
    "new_encodings = tokenizer(new_text, truncation=True, padding='max_length', max_length=25, return_tensors='tf')\n",
    "predicted_content, predicted_wording = model.predict(new_encodings['input_ids'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
