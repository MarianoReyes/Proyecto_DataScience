{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jose\\AppData\\Local\\Temp\\ipykernel_16452\\2396692039.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['text'] = data['text'].str.lower().str.replace('[^a-z\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Preparación de Datos\n",
    "data = pd.read_csv('data/normalized_merged_data.csv')\n",
    "data['text'] = data['text'].str.lower().str.replace('[^a-z\\s]', '')\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "train_encodings = tokenizer(train['text'].tolist(), truncation=True, padding='max_length', max_length=25, return_tensors='tf')\n",
    "val_encodings = tokenizer(val['text'].tolist(), truncation=True, padding='max_length', max_length=25, return_tensors='tf')\n",
    "test_encodings = tokenizer(test['text'].tolist(), truncation=True, padding='max_length', max_length=25, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# 2. Definición del Modelo\n",
    "base_model = TFGPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
    "input_layer = tf.keras.layers.Input(shape=(25,), dtype=tf.int32)\n",
    "sequence_output = base_model(input_layer)[0]\n",
    "cls_token = sequence_output[:, 0, :]\n",
    "content_head = tf.keras.layers.Dense(1, activation='sigmoid', name='content')(cls_token)\n",
    "wording_head = tf.keras.layers.Dense(1, activation='sigmoid', name='wording')(cls_token)\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=[content_head, wording_head])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 17/144 [==>...........................] - ETA: 1:35:32 - loss: 0.6729 - content_loss: 0.5251 - wording_loss: 0.1478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Entrenamiento\n",
    "model.fit(train_encodings['input_ids'], [train['normalized_content'], train['normalized_wording']], validation_data=(val_encodings['input_ids'], [val['normalized_content'], val['normalized_wording']]), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 guardar modelo\n",
    "model.save('nlp_gpt2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluación\n",
    "losses = model.evaluate(test_encodings['input_ids'], [test['normalized_content'], test['normalized_wording']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Predicción\n",
    "new_text = [\"The Third Wave was an experiment to see how people reacted to a new one leader government.\"]\n",
    "new_encodings = tokenizer(new_text, truncation=True, padding='max_length', max_length=25, return_tensors='tf')\n",
    "predicted_content, predicted_wording = model.predict(new_encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Muestra de graficas evaluando el modelo\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supongamos que ya tienes el modelo entrenado y que has realizado predicciones en el conjunto de prueba\n",
    "predicted_content, predicted_wording = model.predict(test_encodings['input_ids'])\n",
    "\n",
    "# Obtener los valores reales del CSV\n",
    "actual_content = test['normalized_content']\n",
    "actual_wording = test['normalized_wording']\n",
    "\n",
    "# Crear un scatter plot para comparar las predicciones con los valores reales\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(actual_content, predicted_content, alpha=0.5)\n",
    "plt.title('Comparación de Content (Valores Reales vs. Predicciones)')\n",
    "plt.xlabel('Valor Real')\n",
    "plt.ylabel('Predicción')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(actual_wording, predicted_wording, alpha=0.5)\n",
    "plt.title('Comparación de Wording (Valores Reales vs. Predicciones)')\n",
    "plt.xlabel('Valor Real')\n",
    "plt.ylabel('Predicción')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Crear histogramas de errores\n",
    "error_content = actual_content - predicted_content\n",
    "error_wording = actual_wording - predicted_wording\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(error_content, bins=20, color='blue', alpha=0.7)\n",
    "plt.title('Histograma de Errores en Content')\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(error_wording, bins=20, color='green', alpha=0.7)\n",
    "plt.title('Histograma de Errores en Wording')\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
