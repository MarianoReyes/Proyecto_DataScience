{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport random\nimport torch.nn as nn\nimport os\nfrom torch.utils.data import Dataset,DataLoader\nfrom transformers import AutoTokenizer,AutoModelForSequenceClassification\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"f266cd7b-479b-454e-bc4a-0decd3dba237","_cell_guid":"30b796ab-c0b4-4b88-af6a-feae5f9f5ba2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-29T14:03:52.994667Z","iopub.execute_input":"2023-10-29T14:03:52.995401Z","iopub.status.idle":"2023-10-29T14:03:53.000815Z","shell.execute_reply.started":"2023-10-29T14:03:52.995361Z","shell.execute_reply":"2023-10-29T14:03:52.999967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    \n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    #设置torch模块的种子\n    torch.manual_seed(seed)\n    #设置cuda相关种子\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=42)","metadata":{"_uuid":"6cc891fb-844a-4712-94c2-8747a4d89592","_cell_guid":"8d8d50f2-0f55-4b71-ab26-0425b465a9c1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-29T14:03:53.006577Z","iopub.execute_input":"2023-10-29T14:03:53.006914Z","iopub.status.idle":"2023-10-29T14:03:53.013552Z","shell.execute_reply.started":"2023-10-29T14:03:53.006869Z","shell.execute_reply":"2023-10-29T14:03:53.012721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n\nprompts_train = pd.read_csv(data_path + \"prompts_train.csv\")\nprompts_test = pd.read_csv(data_path + \"prompts_test.csv\")\nsummaries_train = pd.read_csv(data_path + \"summaries_train.csv\")\nsummaries_test = pd.read_csv(data_path + \"summaries_test.csv\")\nsample_submission = pd.read_csv(data_path + \"sample_submission.csv\")\n\ntrain = summaries_train.merge(prompts_train, on=\"prompt_id\")\ntest = summaries_test.merge(prompts_test, on=\"prompt_id\")\n\ntrain","metadata":{"_uuid":"92c5a01c-1b65-45be-ba3a-7ce2627232f8","_cell_guid":"9d80d13d-287e-4050-bcf5-ce065c166a7c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-29T14:03:53.033368Z","iopub.execute_input":"2023-10-29T14:03:53.034015Z","iopub.status.idle":"2023-10-29T14:03:53.111200Z","shell.execute_reply.started":"2023-10-29T14:03:53.033990Z","shell.execute_reply":"2023-10-29T14:03:53.110331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/debertav3base\")\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/input/debertav3base\")","metadata":{"_uuid":"d117e5b7-4f78-421f-b85c-fe50651bb5cf","_cell_guid":"a9eb5c3d-56f1-48de-959d-28e0e3d67bee","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-29T14:03:53.112887Z","iopub.execute_input":"2023-10-29T14:03:53.113177Z","iopub.status.idle":"2023-10-29T14:03:56.816806Z","shell.execute_reply.started":"2023-10-29T14:03:53.113152Z","shell.execute_reply":"2023-10-29T14:03:56.816048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CommonLitDataset(Dataset):\n    def __init__(self,data:pd.DataFrame,tokenizer):\n        super(CommonLitDataset,self).__init__()\n        self.data = data\n        self.tokenizer = tokenizer\n        \n        self.text = self.data[\"text\"].tolist()\n        self.text = self.get_token(self.text)                \n        \n    def __getitem__(self,index):\n        input_ids = self.text['input_ids'][index]\n        attention_mask = self.text['attention_mask'][index]\n        \n        if 'content' not in self.data.columns:\n            return {'input_ids':input_ids,\n                   'attention_mask':attention_mask}\n        else:\n            content = self.data[\"content\"].tolist()[index]\n            wording = self.data[\"wording\"].tolist()[index]\n\n            return {'input_ids':input_ids,\n                    'attention_mask':attention_mask,\n                    'content':content,\n                    'wording':wording}\n            \n            \n    def __len__(self):\n        return len(self.data['text'])\n    \n    def get_token(self,text):\n        return self.tokenizer.batch_encode_plus(text,\n                                         padding=True,\n                                         truncation=True,\n                                         max_length=512,\n                                         return_tensors=\"pt\")","metadata":{"_uuid":"f82deda7-b6c5-4e9d-a330-03417f787a43","_cell_guid":"751960f4-32fb-4fc7-bfff-e4035648a69f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-29T14:03:56.818057Z","iopub.execute_input":"2023-10-29T14:03:56.818341Z","iopub.status.idle":"2023-10-29T14:03:56.827417Z","shell.execute_reply.started":"2023-10-29T14:03:56.818306Z","shell.execute_reply":"2023-10-29T14:03:56.826480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 12\n\ntarget = ['content','wording']\n\ndata = train.loc[:,'text']\nlabel = train.loc[:,target]\n\ntrain_data,val_data,train_label,val_label = train_test_split(data,label,test_size=0.2,random_state=42)\n\ntrain_data = pd.concat([train_data,train_label],axis=1)\nval_data = pd.concat([val_data,val_label],axis=1)\n\ntrain_dataset = CommonLitDataset(train_data,tokenizer)\ntrain_loader = DataLoader(train_dataset,shuffle=False,batch_size=batch_size)\n    \nval_dataset = CommonLitDataset(val_data,tokenizer)\nval_loader = DataLoader(val_dataset,shuffle=False,batch_size=batch_size)","metadata":{"_uuid":"94565267-1003-4bf0-a076-19187b53ef34","_cell_guid":"8f4a382a-2a34-4890-ab5b-ce61143b2d4d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-29T14:03:56.829870Z","iopub.execute_input":"2023-10-29T14:03:56.830473Z","iopub.status.idle":"2023-10-29T14:04:01.836404Z","shell.execute_reply.started":"2023-10-29T14:03:56.830438Z","shell.execute_reply":"2023-10-29T14:04:01.835357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Deberta(nn.Module):\n    def __init__(self,deberta):\n        super(Deberta,self).__init__()\n        self.deberta = deberta\n        self.model = nn.Sequential(nn.Dropout(0.1),\n                                   nn.Linear(2,768),\n                                  nn.ReLU(),\n                                  nn.Linear(768,256),\n                                  nn.ReLU(),\n                                  nn.Linear(256,2))\n        \n    def forward(self,input_ids,attention_mask):\n        x = self.deberta(input_ids=input_ids,attention_mask=attention_mask)\n        x = x[0].type(torch.float32)\n        x =self.model(x)\n        return x","metadata":{"_uuid":"e3f0fd02-11ac-47f1-afc0-3ef05483b8e9","_cell_guid":"98fe9f81-a0cb-4f96-b9c8-1357116ba8a0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-29T14:04:01.837630Z","iopub.execute_input":"2023-10-29T14:04:01.837967Z","iopub.status.idle":"2023-10-29T14:04:01.844537Z","shell.execute_reply.started":"2023-10-29T14:04:01.837942Z","shell.execute_reply":"2023-10-29T14:04:01.843682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = Deberta(model).to(device)\noptim = torch.optim.Adam(model.parameters(),lr=1.5e-5)\ncriterion = nn.MSELoss()","metadata":{"_uuid":"52e64418-7209-4937-8784-29dcf6e0e473","_cell_guid":"d6c708b1-b311-4529-b854-f790216ec4b1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-29T14:04:01.845787Z","iopub.execute_input":"2023-10-29T14:04:01.846377Z","iopub.status.idle":"2023-10-29T14:04:02.062051Z","shell.execute_reply.started":"2023-10-29T14:04:01.846336Z","shell.execute_reply":"2023-10-29T14:04:02.061224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 30\n\nmodel.train()\n\nfor epoch in range(epochs):\n    running_loss = 0\n    step = 0\n    for data in train_loader:\n        input_ids = data['input_ids'].to(device)\n        attention_mask = data['attention_mask'].to(device)\n        content = data['content'].type(torch.float32).to(device)\n        wording = data['wording'].type(torch.float32).to(device)\n\n        optim.zero_grad()\n        outputs = model(input_ids,attention_mask)\n        loss = criterion(outputs[:,0],content) + criterion(outputs[:,1],wording)\n        loss.backward()\n        optim.step()\n        if step % 500 == 0:\n            print(\"Epoch {}, Step {}, Loss: {}\".format(epoch+1, step, loss.item()))\n\n        running_loss += loss.item()\n        step = step + 1\n\n    print(f\"Epoch {epoch+1} Loss: {running_loss / len(train_loader)}\")\n        \n    model.eval()\n    with torch.no_grad():\n        val_loss = 0.0\n        step = 0\n        for data in val_loader:\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            content = data['content'].type(torch.float32).to(device)\n            wording = data['wording'].type(torch.float32).to(device)\n            \n            outputs = model(input_ids,attention_mask)\n            val_loss+=criterion(outputs[:,0],content)+criterion(outputs[:,1],wording)\n                \n        print(f\"Validation Loss: {val_loss / len(val_loader)}\")\n    model.train()","metadata":{"_uuid":"27860552-e75b-47f9-9b22-704f3cd64259","_cell_guid":"05a83fb6-22ac-44ae-86e8-a5508d0380a8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-29T14:04:02.063425Z","iopub.execute_input":"2023-10-29T14:04:02.064107Z","iopub.status.idle":"2023-10-29T18:07:24.160595Z","shell.execute_reply.started":"2023-10-29T14:04:02.064072Z","shell.execute_reply":"2023-10-29T18:07:24.159587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\npredict = []\n\ntest_dataset = CommonLitDataset(test,tokenizer)\ntest_loader = DataLoader(test_dataset,shuffle=False,batch_size=batch_size)\n\nwith torch.no_grad():\n    for data in test_loader:\n        input_ids = data['input_ids'].to(device)\n        attention_mask = data['attention_mask'].to(device)\n        \n        outputs = model(input_ids,attention_mask)\n        predict.extend(outputs.cpu().numpy())","metadata":{"_uuid":"998d7197-13a4-4cb7-904c-e98881b4ef8e","_cell_guid":"d29ae7bf-ac1f-428a-b2c8-0ce31fec269a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-29T18:07:24.162186Z","iopub.execute_input":"2023-10-29T18:07:24.162656Z","iopub.status.idle":"2023-10-29T18:07:24.193544Z","shell.execute_reply.started":"2023-10-29T18:07:24.162621Z","shell.execute_reply":"2023-10-29T18:07:24.192538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'student_id':test['student_id'],\n    'content':[pred[0] for pred in predict],\n    'wording':[pred[1] for pred in predict]\n}) \nsubmission.to_csv('submission.csv',index=False)","metadata":{"_uuid":"6d0fc89e-bf1e-4efa-b3cb-73460472e62d","_cell_guid":"75e2d027-0305-4d25-a974-bcf9e6188e5d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-29T18:07:24.197482Z","iopub.execute_input":"2023-10-29T18:07:24.197747Z","iopub.status.idle":"2023-10-29T18:07:24.205587Z","shell.execute_reply.started":"2023-10-29T18:07:24.197724Z","shell.execute_reply":"2023-10-29T18:07:24.203910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"_uuid":"42dcd437-611a-48bf-9794-50e155f9625f","_cell_guid":"635ac934-866d-48ed-a0f1-f2ff57678521","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-29T18:07:24.206842Z","iopub.execute_input":"2023-10-29T18:07:24.209941Z","iopub.status.idle":"2023-10-29T18:07:24.225094Z","shell.execute_reply.started":"2023-10-29T18:07:24.209905Z","shell.execute_reply":"2023-10-29T18:07:24.223955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nuevo resumen que deseas predecir\nnuevo_resumen = \"Este es el nuevo resumen que deseas predecir.\"\n\n# Tokeniza y codifica el nuevo resumen\nnuevo_resumen_encoded = tokenizer.encode_plus(\n    nuevo_resumen,\n    padding=True,\n    truncation=True,\n    max_length=512,\n    return_tensors=\"pt\"\n)\n\n# Realiza la predicción con el modelo\nwith torch.no_grad():\n    input_ids = nuevo_resumen_encoded['input_ids'].to(device)\n    attention_mask = nuevo_resumen_encoded['attention_mask'].to(device)\n    \n    outputs = model(input_ids, attention_mask)\n    content_prediction = outputs[0][0].item()  # Predicción para \"content\"\n    wording_prediction = outputs[0][1].item()  # Predicción para \"wording\"\n\n# Imprime las predicciones\nprint(f'Predicción para \"content\": {content_prediction}')\nprint(f'Predicción para \"wording\": {wording_prediction}')","metadata":{"_uuid":"a95ce88d-9d5d-45cf-8b93-151843af1728","_cell_guid":"04712c8a-436b-4cd4-9e4d-2081d4474bb4","collapsed":false,"execution":{"iopub.status.busy":"2023-10-29T18:07:24.226793Z","iopub.execute_input":"2023-10-29T18:07:24.227137Z","iopub.status.idle":"2023-10-29T18:07:24.267360Z","shell.execute_reply.started":"2023-10-29T18:07:24.227105Z","shell.execute_reply":"2023-10-29T18:07:24.266266Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Supongamos que \"model\" es tu modelo PyTorch entrenado\ntorch.save(model.state_dict(), '/kaggle/working/deberta_nlp.pth')","metadata":{"_uuid":"b600d2fb-94d1-4d0a-becf-195e62ffdc84","_cell_guid":"816492ed-e324-4545-820a-7e0519e2d929","collapsed":false,"execution":{"iopub.status.busy":"2023-10-29T18:07:24.268712Z","iopub.execute_input":"2023-10-29T18:07:24.269105Z","iopub.status.idle":"2023-10-29T18:07:25.898670Z","shell.execute_reply.started":"2023-10-29T18:07:24.269067Z","shell.execute_reply":"2023-10-29T18:07:25.897549Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nuevo_resumen = \"During the 1967 Third Wave experiment at Cubberley High School, students experienced a rapid transformation in their behavior and beliefs. The experiment aimed to demonstrate how easily people can be swayed to support authoritarian ideologies. Under the leadership of their teacher, Ron Jones, students adopted a strict code of conduct and authoritarian structure in a matter of days. They were highly engaged in this \"\"movement,\"\" even to the point of shutting out non-members and eagerly awaiting a televised announcement by a supposed presidential candidate from the movement. The experiment ended when Ron Jones felt it was spiraling out of control, illustrating the potential danger of such movements.\"\n# Tokeniza y codifica el nuevo resumen\nnuevo_resumen_encoded = tokenizer.encode_plus(\n    nuevo_resumen,\n    padding=True,\n    truncation=True,\n    max_length=512,\n    return_tensors=\"pt\"\n)\n# Realiza la predicción con el modelo\nwith torch.no_grad():\n    input_ids = nuevo_resumen_encoded['input_ids'].to(device)\n    attention_mask = nuevo_resumen_encoded['attention_mask'].to(device)\n    \n    outputs = model(input_ids, attention_mask)\n    content_prediction = outputs[0][0].item()  # Predicción para \"content\"\n    wording_prediction = outputs[0][1].item()  # Predicción para \"wording\"\n\n# Imprime las predicciones\nprint(f'Predicción para \"content\": {content_prediction}')\nprint(f'Predicción para \"wording\": {wording_prediction}')","metadata":{"_uuid":"233c8b40-d59c-42e2-8df9-07370e593fc5","_cell_guid":"485248c6-e114-4ff7-9003-997d105d44db","collapsed":false,"execution":{"iopub.status.busy":"2023-10-29T18:07:25.900614Z","iopub.execute_input":"2023-10-29T18:07:25.901031Z","iopub.status.idle":"2023-10-29T18:07:25.934915Z","shell.execute_reply.started":"2023-10-29T18:07:25.900992Z","shell.execute_reply":"2023-10-29T18:07:25.934005Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(predict)","metadata":{"_uuid":"7d1ec265-719a-4e0c-85a5-568210043a69","_cell_guid":"c0fa5e54-5504-4e90-b888-5a6c17e00343","collapsed":false,"execution":{"iopub.status.busy":"2023-10-29T18:07:25.935984Z","iopub.execute_input":"2023-10-29T18:07:25.936262Z","iopub.status.idle":"2023-10-29T18:07:25.941430Z","shell.execute_reply.started":"2023-10-29T18:07:25.936238Z","shell.execute_reply":"2023-10-29T18:07:25.940499Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\n\n# Directorio donde se guardará el modelo personalizado\noutput_model_dir = \"/kaggle/working/deberta_final\"\n\n# Asegúrate de que el directorio exista\nos.makedirs(output_model_dir, exist_ok=True)\n\n# Guarda los pesos del modelo en el nuevo directorio\ntorch.save(model.state_dict(), os.path.join(output_model_dir, \"model_state_dict.pth\"))\n\n# Guarda otros archivos relacionados con el modelo (si los tienes)\n# Por ejemplo, si tienes configuraciones personalizadas, guárdalas también.\n\n# Opcional: guarda el tokenizador en el mismo directorio\ntokenizer.save_pretrained(output_model_dir)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-29T18:30:07.970191Z","iopub.execute_input":"2023-10-29T18:30:07.971040Z","iopub.status.idle":"2023-10-29T18:30:09.357741Z","shell.execute_reply.started":"2023-10-29T18:30:07.971005Z","shell.execute_reply":"2023-10-29T18:30:09.356798Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/deberta_final/tokenizer_config.json',\n '/kaggle/working/deberta_final/special_tokens_map.json',\n '/kaggle/working/deberta_final/spm.model',\n '/kaggle/working/deberta_final/added_tokens.json',\n '/kaggle/working/deberta_final/tokenizer.json')"},"metadata":{}}]}]}